{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Vehicle_Speed_Recommendation_System.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "2y1r04XnLFG7"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohjbxyAKQKu9"
      },
      "source": [
        "from google.colab import files"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7CgpmdW5jdGlvbiBfdXBsb2FkRmlsZXMoaW5wdXRJZCwgb3V0cHV0SWQpIHsKICBjb25zdCBzdGVwcyA9IHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCk7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICAvLyBDYWNoZSBzdGVwcyBvbiB0aGUgb3V0cHV0RWxlbWVudCB0byBtYWtlIGl0IGF2YWlsYWJsZSBmb3IgdGhlIG5leHQgY2FsbAogIC8vIHRvIHVwbG9hZEZpbGVzQ29udGludWUgZnJvbSBQeXRob24uCiAgb3V0cHV0RWxlbWVudC5zdGVwcyA9IHN0ZXBzOwoKICByZXR1cm4gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpOwp9CgovLyBUaGlzIGlzIHJvdWdobHkgYW4gYXN5bmMgZ2VuZXJhdG9yIChub3Qgc3VwcG9ydGVkIGluIHRoZSBicm93c2VyIHlldCksCi8vIHdoZXJlIHRoZXJlIGFyZSBtdWx0aXBsZSBhc3luY2hyb25vdXMgc3RlcHMgYW5kIHRoZSBQeXRob24gc2lkZSBpcyBnb2luZwovLyB0byBwb2xsIGZvciBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcC4KLy8gVGhpcyB1c2VzIGEgUHJvbWlzZSB0byBibG9jayB0aGUgcHl0aG9uIHNpZGUgb24gY29tcGxldGlvbiBvZiBlYWNoIHN0ZXAsCi8vIHRoZW4gcGFzc2VzIHRoZSByZXN1bHQgb2YgdGhlIHByZXZpb3VzIHN0ZXAgYXMgdGhlIGlucHV0IHRvIHRoZSBuZXh0IHN0ZXAuCmZ1bmN0aW9uIF91cGxvYWRGaWxlc0NvbnRpbnVlKG91dHB1dElkKSB7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICBjb25zdCBzdGVwcyA9IG91dHB1dEVsZW1lbnQuc3RlcHM7CgogIGNvbnN0IG5leHQgPSBzdGVwcy5uZXh0KG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSk7CiAgcmV0dXJuIFByb21pc2UucmVzb2x2ZShuZXh0LnZhbHVlLnByb21pc2UpLnRoZW4oKHZhbHVlKSA9PiB7CiAgICAvLyBDYWNoZSB0aGUgbGFzdCBwcm9taXNlIHZhbHVlIHRvIG1ha2UgaXQgYXZhaWxhYmxlIHRvIHRoZSBuZXh0CiAgICAvLyBzdGVwIG9mIHRoZSBnZW5lcmF0b3IuCiAgICBvdXRwdXRFbGVtZW50Lmxhc3RQcm9taXNlVmFsdWUgPSB2YWx1ZTsKICAgIHJldHVybiBuZXh0LnZhbHVlLnJlc3BvbnNlOwogIH0pOwp9CgovKioKICogR2VuZXJhdG9yIGZ1bmN0aW9uIHdoaWNoIGlzIGNhbGxlZCBiZXR3ZWVuIGVhY2ggYXN5bmMgc3RlcCBvZiB0aGUgdXBsb2FkCiAqIHByb2Nlc3MuCiAqIEBwYXJhbSB7c3RyaW5nfSBpbnB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIGlucHV0IGZpbGUgcGlja2VyIGVsZW1lbnQuCiAqIEBwYXJhbSB7c3RyaW5nfSBvdXRwdXRJZCBFbGVtZW50IElEIG9mIHRoZSBvdXRwdXQgZGlzcGxheS4KICogQHJldHVybiB7IUl0ZXJhYmxlPCFPYmplY3Q+fSBJdGVyYWJsZSBvZiBuZXh0IHN0ZXBzLgogKi8KZnVuY3Rpb24qIHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IGlucHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKGlucHV0SWQpOwogIGlucHV0RWxlbWVudC5kaXNhYmxlZCA9IGZhbHNlOwoKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIG91dHB1dEVsZW1lbnQuaW5uZXJIVE1MID0gJyc7CgogIGNvbnN0IHBpY2tlZFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgaW5wdXRFbGVtZW50LmFkZEV2ZW50TGlzdGVuZXIoJ2NoYW5nZScsIChlKSA9PiB7CiAgICAgIHJlc29sdmUoZS50YXJnZXQuZmlsZXMpOwogICAgfSk7CiAgfSk7CgogIGNvbnN0IGNhbmNlbCA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2J1dHRvbicpOwogIGlucHV0RWxlbWVudC5wYXJlbnRFbGVtZW50LmFwcGVuZENoaWxkKGNhbmNlbCk7CiAgY2FuY2VsLnRleHRDb250ZW50ID0gJ0NhbmNlbCB1cGxvYWQnOwogIGNvbnN0IGNhbmNlbFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgY2FuY2VsLm9uY2xpY2sgPSAoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9OwogIH0pOwoKICAvLyBXYWl0IGZvciB0aGUgdXNlciB0byBwaWNrIHRoZSBmaWxlcy4KICBjb25zdCBmaWxlcyA9IHlpZWxkIHsKICAgIHByb21pc2U6IFByb21pc2UucmFjZShbcGlja2VkUHJvbWlzZSwgY2FuY2VsUHJvbWlzZV0pLAogICAgcmVzcG9uc2U6IHsKICAgICAgYWN0aW9uOiAnc3RhcnRpbmcnLAogICAgfQogIH07CgogIGNhbmNlbC5yZW1vdmUoKTsKCiAgLy8gRGlzYWJsZSB0aGUgaW5wdXQgZWxlbWVudCBzaW5jZSBmdXJ0aGVyIHBpY2tzIGFyZSBub3QgYWxsb3dlZC4KICBpbnB1dEVsZW1lbnQuZGlzYWJsZWQgPSB0cnVlOwoKICBpZiAoIWZpbGVzKSB7CiAgICByZXR1cm4gewogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgICAgfQogICAgfTsKICB9CgogIGZvciAoY29uc3QgZmlsZSBvZiBmaWxlcykgewogICAgY29uc3QgbGkgPSBkb2N1bWVudC5jcmVhdGVFbGVtZW50KCdsaScpOwogICAgbGkuYXBwZW5kKHNwYW4oZmlsZS5uYW1lLCB7Zm9udFdlaWdodDogJ2JvbGQnfSkpOwogICAgbGkuYXBwZW5kKHNwYW4oCiAgICAgICAgYCgke2ZpbGUudHlwZSB8fCAnbi9hJ30pIC0gJHtmaWxlLnNpemV9IGJ5dGVzLCBgICsKICAgICAgICBgbGFzdCBtb2RpZmllZDogJHsKICAgICAgICAgICAgZmlsZS5sYXN0TW9kaWZpZWREYXRlID8gZmlsZS5sYXN0TW9kaWZpZWREYXRlLnRvTG9jYWxlRGF0ZVN0cmluZygpIDoKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgJ24vYSd9IC0gYCkpOwogICAgY29uc3QgcGVyY2VudCA9IHNwYW4oJzAlIGRvbmUnKTsKICAgIGxpLmFwcGVuZENoaWxkKHBlcmNlbnQpOwoKICAgIG91dHB1dEVsZW1lbnQuYXBwZW5kQ2hpbGQobGkpOwoKICAgIGNvbnN0IGZpbGVEYXRhUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICAgIGNvbnN0IHJlYWRlciA9IG5ldyBGaWxlUmVhZGVyKCk7CiAgICAgIHJlYWRlci5vbmxvYWQgPSAoZSkgPT4gewogICAgICAgIHJlc29sdmUoZS50YXJnZXQucmVzdWx0KTsKICAgICAgfTsKICAgICAgcmVhZGVyLnJlYWRBc0FycmF5QnVmZmVyKGZpbGUpOwogICAgfSk7CiAgICAvLyBXYWl0IGZvciB0aGUgZGF0YSB0byBiZSByZWFkeS4KICAgIGxldCBmaWxlRGF0YSA9IHlpZWxkIHsKICAgICAgcHJvbWlzZTogZmlsZURhdGFQcm9taXNlLAogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbnRpbnVlJywKICAgICAgfQogICAgfTsKCiAgICAvLyBVc2UgYSBjaHVua2VkIHNlbmRpbmcgdG8gYXZvaWQgbWVzc2FnZSBzaXplIGxpbWl0cy4gU2VlIGIvNjIxMTU2NjAuCiAgICBsZXQgcG9zaXRpb24gPSAwOwogICAgd2hpbGUgKHBvc2l0aW9uIDwgZmlsZURhdGEuYnl0ZUxlbmd0aCkgewogICAgICBjb25zdCBsZW5ndGggPSBNYXRoLm1pbihmaWxlRGF0YS5ieXRlTGVuZ3RoIC0gcG9zaXRpb24sIE1BWF9QQVlMT0FEX1NJWkUpOwogICAgICBjb25zdCBjaHVuayA9IG5ldyBVaW50OEFycmF5KGZpbGVEYXRhLCBwb3NpdGlvbiwgbGVuZ3RoKTsKICAgICAgcG9zaXRpb24gKz0gbGVuZ3RoOwoKICAgICAgY29uc3QgYmFzZTY0ID0gYnRvYShTdHJpbmcuZnJvbUNoYXJDb2RlLmFwcGx5KG51bGwsIGNodW5rKSk7CiAgICAgIHlpZWxkIHsKICAgICAgICByZXNwb25zZTogewogICAgICAgICAgYWN0aW9uOiAnYXBwZW5kJywKICAgICAgICAgIGZpbGU6IGZpbGUubmFtZSwKICAgICAgICAgIGRhdGE6IGJhc2U2NCwKICAgICAgICB9LAogICAgICB9OwogICAgICBwZXJjZW50LnRleHRDb250ZW50ID0KICAgICAgICAgIGAke01hdGgucm91bmQoKHBvc2l0aW9uIC8gZmlsZURhdGEuYnl0ZUxlbmd0aCkgKiAxMDApfSUgZG9uZWA7CiAgICB9CiAgfQoKICAvLyBBbGwgZG9uZS4KICB5aWVsZCB7CiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICB9CiAgfTsKfQoKc2NvcGUuZ29vZ2xlID0gc2NvcGUuZ29vZ2xlIHx8IHt9OwpzY29wZS5nb29nbGUuY29sYWIgPSBzY29wZS5nb29nbGUuY29sYWIgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYi5fZmlsZXMgPSB7CiAgX3VwbG9hZEZpbGVzLAogIF91cGxvYWRGaWxlc0NvbnRpbnVlLAp9Owp9KShzZWxmKTsK",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": "OK"
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "TWRbSb7CQVKY",
        "outputId": "8fff08c4-42d9-404d-e187-44f7db2898cc"
      },
      "source": [
        "uploaded= files.upload()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-fabdae81-d2e0-4776-b748-e80e5d69f40c\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-fabdae81-d2e0-4776-b748-e80e5d69f40c\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving dataset.zip to dataset.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNLb14NdQMGt"
      },
      "source": [
        "import zipfile\n",
        "import io\n",
        "zf = zipfile.ZipFile(io.BytesIO(uploaded['dataset.zip']), \"r\")\n",
        "zf.extractall()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oHozlKVNW36M",
        "outputId": "e6e76a77-eb65-4198-89ec-b52a289f9639"
      },
      "source": [
        "os.listdir('Road Data')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Test', 'Train']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TEuDEI0ELMpx"
      },
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "        rotation_range=40,\n",
        "        width_shift_range=0.2,\n",
        "        height_shift_range=0.2,\n",
        "        rescale=1./255,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True,\n",
        "        fill_mode='nearest')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2EUE5wdaLRcq"
      },
      "source": [
        "val_datagen = ImageDataGenerator(rescale =1.0/255.)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJBjtecuLT0n",
        "outputId": "688b5b8b-fb3d-4f0b-e5b8-dcb1904ed8a4"
      },
      "source": [
        "training_set1 = train_datagen.flow_from_directory('Road Data/Train',\n",
        "                                                 target_size = (100, 100),\n",
        "                                                 batch_size = 10,\n",
        "                                                 class_mode = 'binary')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 24 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "twFRtQqJLfzV",
        "outputId": "e535ca82-f627-47d6-9cab-0222aeb6d06a"
      },
      "source": [
        "training_set2 = train_datagen.flow_from_directory('Traffic Data/Train',\n",
        "                                                 target_size = (100, 100),\n",
        "                                                 batch_size = 10,\n",
        "                                                 class_mode = 'categorical')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 21 images belonging to 3 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B3D9ZgrTLiCg",
        "outputId": "3813bd51-1a01-43c3-a4b9-473329071c0f"
      },
      "source": [
        "val_set1 = val_datagen.flow_from_directory('Road Data/Test',\n",
        "                                            target_size = (100, 100),\n",
        "                                            batch_size = 8,\n",
        "                                            class_mode = 'binary')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 14 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BIGNCOPULo_a",
        "outputId": "ebf56649-eea1-48ce-f60a-f70c999a10af"
      },
      "source": [
        "val_set2 = train_datagen.flow_from_directory('Traffic Data/Test',\n",
        "                                                 target_size = (100, 100),\n",
        "                                                 batch_size = 10,\n",
        "                                                 class_mode = 'categorical')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 6 images belonging to 3 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FvWrzSZkLvkC",
        "outputId": "dc35867b-4c65-44b6-84b5-bed7df79e5e3"
      },
      "source": [
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
        "    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-01-03 09:39:43--  https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 64.233.189.128, 74.125.203.128, 74.125.204.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|64.233.189.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 87910968 (84M) [application/x-hdf]\n",
            "Saving to: ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’\n",
            "\n",
            "/tmp/inception_v3_w 100%[===================>]  83.84M   134MB/s    in 0.6s    \n",
            "\n",
            "2021-01-03 09:39:44 (134 MB/s) - ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’ saved [87910968/87910968]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8WFK_gTfLzrL"
      },
      "source": [
        "local_weight_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJN9TQKLL-_g"
      },
      "source": [
        "pretrained_model = InceptionV3(input_shape= (100,100,3),include_top = False,weights = None)\n",
        "\n",
        "pretrained_model.load_weights(local_weight_file)\n",
        "\n",
        "for layer in pretrained_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "#pretrained_model.summary()\n",
        "\n",
        "last_layer = pretrained_model.get_layer('mixed8')\n",
        "last_output = last_layer.output\n",
        "\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBGU-yFEMGQx"
      },
      "source": [
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self,epochs,logs={}):\n",
        "        if(logs.get('val_acc')>=0.70):\n",
        "            print(\"\\nReached 70% accuracy so cancelling training!\")\n",
        "            self.model.stop_training = True"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NnQgDOGTMZ5P"
      },
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "x = layers.Flatten()(last_output)\n",
        "x = layers.Dense(1024,activation = 'relu')(x)\n",
        "x = layers.Dropout(.2)(x)\n",
        "x = layers.Dense(1,activation ='sigmoid')(x)\n",
        "model1 = Model(pretrained_model.input,x)\n",
        "\n",
        "model1.compile(optimizer=RMSprop(lr=0.01), loss = 'binary_crossentropy', metrics = 'acc')"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eiD-E0wzMUl4"
      },
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "x = layers.Flatten()(last_output)\n",
        "x = layers.Dense(1024,activation = 'relu')(x)\n",
        "x = layers.Dropout(.2)(x)\n",
        "x = layers.Dense(3,activation ='softmax')(x)\n",
        "model2 = Model(pretrained_model.input,x)\n",
        "\n",
        "model2.compile(\n",
        "    optimizer='adam', \n",
        "    loss=tf.keras.losses.CategoricalCrossentropy(), \n",
        "    metrics=['acc'])"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kXCOv_PZMzh-",
        "outputId": "400bc54d-ddee-4961-e7a4-1443221e5507"
      },
      "source": [
        "my_callback_object = myCallback()\n",
        "history1 = model1.fit_generator(\n",
        "    training_set1,validation_data =val_set1,epochs=100, verbose =1,callbacks=[my_callback_object])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "3/3 [==============================] - 6s 1s/step - loss: 22.8082 - acc: 0.4571 - val_loss: 20.7638 - val_acc: 0.5000\n",
            "Epoch 2/100\n",
            "3/3 [==============================] - 1s 448ms/step - loss: 22.4224 - acc: 0.6333 - val_loss: 3.7513 - val_acc: 0.7143\n",
            "\n",
            "Reached 70% accuracy so cancelling training!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-D52vPQyNATH",
        "outputId": "7393b37d-1082-47be-885a-e46b877cf2f9"
      },
      "source": [
        "history2 = model2.fit_generator(\n",
        "    training_set2,validation_data = val_set2,\n",
        "    epochs=100, verbose =1,callbacks=[my_callback_object])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 6s 1s/step - loss: 2.2048 - acc: 0.2860 - val_loss: 2.5296 - val_acc: 0.3333\n",
            "Epoch 2/100\n",
            "3/3 [==============================] - 1s 471ms/step - loss: 1.6181 - acc: 0.6234 - val_loss: 1.8096 - val_acc: 0.0000e+00\n",
            "Epoch 3/100\n",
            "3/3 [==============================] - 1s 357ms/step - loss: 1.4776 - acc: 0.5234 - val_loss: 2.9482 - val_acc: 0.3333\n",
            "Epoch 4/100\n",
            "3/3 [==============================] - 1s 485ms/step - loss: 1.5141 - acc: 0.6721 - val_loss: 2.0570 - val_acc: 0.5000\n",
            "Epoch 5/100\n",
            "3/3 [==============================] - 1s 367ms/step - loss: 1.0645 - acc: 0.6185 - val_loss: 1.5614 - val_acc: 0.5000\n",
            "Epoch 6/100\n",
            "3/3 [==============================] - 1s 286ms/step - loss: 0.7602 - acc: 0.6946 - val_loss: 1.3619 - val_acc: 0.5000\n",
            "Epoch 7/100\n",
            "3/3 [==============================] - 1s 461ms/step - loss: 1.1198 - acc: 0.6082 - val_loss: 1.8112 - val_acc: 0.5000\n",
            "Epoch 8/100\n",
            "3/3 [==============================] - 1s 280ms/step - loss: 0.5406 - acc: 0.8423 - val_loss: 1.4358 - val_acc: 0.6667\n",
            "Epoch 9/100\n",
            "3/3 [==============================] - 1s 371ms/step - loss: 0.4555 - acc: 0.8808 - val_loss: 2.9519 - val_acc: 0.5000\n",
            "Epoch 10/100\n",
            "3/3 [==============================] - 1s 275ms/step - loss: 1.2307 - acc: 0.5857 - val_loss: 0.7571 - val_acc: 0.6667\n",
            "Epoch 11/100\n",
            "3/3 [==============================] - 1s 298ms/step - loss: 0.4132 - acc: 0.7798 - val_loss: 3.0115 - val_acc: 0.5000\n",
            "Epoch 12/100\n",
            "3/3 [==============================] - 1s 343ms/step - loss: 1.5113 - acc: 0.6571 - val_loss: 4.8594 - val_acc: 0.3333\n",
            "Epoch 13/100\n",
            "3/3 [==============================] - 1s 331ms/step - loss: 0.9836 - acc: 0.6185 - val_loss: 1.9866 - val_acc: 0.5000\n",
            "Epoch 14/100\n",
            "3/3 [==============================] - 1s 360ms/step - loss: 1.0974 - acc: 0.6662 - val_loss: 1.8754 - val_acc: 0.6667\n",
            "Epoch 15/100\n",
            "3/3 [==============================] - 1s 289ms/step - loss: 0.2003 - acc: 0.9024 - val_loss: 2.5423 - val_acc: 0.3333\n",
            "Epoch 16/100\n",
            "3/3 [==============================] - 1s 466ms/step - loss: 0.6269 - acc: 0.7652 - val_loss: 2.6035 - val_acc: 0.5000\n",
            "Epoch 17/100\n",
            "3/3 [==============================] - 1s 279ms/step - loss: 0.9444 - acc: 0.6458 - val_loss: 2.2282 - val_acc: 0.1667\n",
            "Epoch 18/100\n",
            "3/3 [==============================] - 1s 359ms/step - loss: 0.2381 - acc: 0.9058 - val_loss: 1.5907 - val_acc: 0.5000\n",
            "Epoch 19/100\n",
            "3/3 [==============================] - 1s 279ms/step - loss: 0.2035 - acc: 0.9387 - val_loss: 1.5375 - val_acc: 0.6667\n",
            "Epoch 20/100\n",
            "3/3 [==============================] - 1s 322ms/step - loss: 0.1450 - acc: 0.9762 - val_loss: 0.6600 - val_acc: 0.6667\n",
            "Epoch 21/100\n",
            "3/3 [==============================] - 1s 311ms/step - loss: 0.2565 - acc: 0.9036 - val_loss: 1.9169 - val_acc: 0.3333\n",
            "Epoch 22/100\n",
            "3/3 [==============================] - 1s 333ms/step - loss: 0.0981 - acc: 1.0000 - val_loss: 2.3057 - val_acc: 0.3333\n",
            "Epoch 23/100\n",
            "3/3 [==============================] - 1s 431ms/step - loss: 0.5227 - acc: 0.7855 - val_loss: 1.4579 - val_acc: 0.5000\n",
            "Epoch 24/100\n",
            "3/3 [==============================] - 1s 324ms/step - loss: 0.5279 - acc: 0.7685 - val_loss: 1.1129 - val_acc: 0.6667\n",
            "Epoch 25/100\n",
            "3/3 [==============================] - 1s 464ms/step - loss: 0.1259 - acc: 0.9524 - val_loss: 2.1821 - val_acc: 0.6667\n",
            "Epoch 26/100\n",
            "3/3 [==============================] - 1s 300ms/step - loss: 0.3646 - acc: 0.8161 - val_loss: 1.4560 - val_acc: 0.6667\n",
            "Epoch 27/100\n",
            "3/3 [==============================] - 1s 297ms/step - loss: 0.0969 - acc: 0.9762 - val_loss: 1.8735 - val_acc: 0.6667\n",
            "Epoch 28/100\n",
            "3/3 [==============================] - 1s 475ms/step - loss: 0.5305 - acc: 0.9058 - val_loss: 1.7086 - val_acc: 0.3333\n",
            "Epoch 29/100\n",
            "3/3 [==============================] - 1s 476ms/step - loss: 0.6448 - acc: 0.7424 - val_loss: 1.8799 - val_acc: 0.6667\n",
            "Epoch 30/100\n",
            "3/3 [==============================] - 1s 295ms/step - loss: 0.5164 - acc: 0.6833 - val_loss: 1.3370 - val_acc: 0.5000\n",
            "Epoch 31/100\n",
            "3/3 [==============================] - 1s 280ms/step - loss: 0.0807 - acc: 0.9637 - val_loss: 1.8901 - val_acc: 0.3333\n",
            "Epoch 32/100\n",
            "3/3 [==============================] - 1s 361ms/step - loss: 1.0258 - acc: 0.7628 - val_loss: 3.2126 - val_acc: 0.3333\n",
            "Epoch 33/100\n",
            "3/3 [==============================] - 1s 357ms/step - loss: 0.2931 - acc: 0.9047 - val_loss: 0.8756 - val_acc: 0.8333\n",
            "\n",
            "Reached 70% accuracy so cancelling training!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yBku31MDh_sH",
        "outputId": "a18713e3-63d1-4583-d56d-47c24bdc2941"
      },
      "source": [
        "!mkdir -p saved_model\r\n",
        "model1.save('saved_model/model1')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: saved_model/model1/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rdOVYW-xnqIq",
        "outputId": "dc760c6e-7544-4747-8ca7-1b24093aee84"
      },
      "source": [
        "model2.save('saved_model/modle2')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: saved_model/modle2/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6EFHTN1NLGa"
      },
      "source": [
        "from keras.models import model_from_json\n",
        "model1_json = model1.to_json()\n",
        "with open(\"model1.json\", \"w\") as json_file:\n",
        "    json_file.write(model1_json)\n",
        "model.save_weights(\"model1.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5uC2RySXNMKu"
      },
      "source": [
        "from keras.models import model_from_json\n",
        "model2_json = model2.to_json()\n",
        "with open(\"model2.json\", \"w\") as json_file:\n",
        "    json_file.write(model2_json)\n",
        "model.save_weights(\"model2.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ntsb5AlJNVnK"
      },
      "source": [
        "model1 = ['good','bad']\n",
        "model2 =['high','mod','low']\n",
        "curr_speed = [i for i in range(0,120)]\n",
        "opp_distance = [i for i in range(0,100)]\n",
        "vis_ = [0,1]\n",
        "time =['mrn','aft','evn','nig']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dhoc7lEyNwMK"
      },
      "source": [
        "from itertools import product"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXLHVjGGNz_F"
      },
      "source": [
        "'''\n",
        "df =[[i,j,k,l,m,n] for i in model1 for j in model2 for k in curr_speed for l in opp_distance for m in vis_ for n in time]\n",
        "data_frame = pd.DataFrame(data =df, columns = ['Road_cond','Traffic_cond','curr_speed','opp_dist','vis','time'])\n",
        "\n",
        "check = data_frame.copy()\n",
        "\n",
        "list_ = []\n",
        "\n",
        "for i in range(len(check)):\n",
        "    if check.loc[i]['vis'] == 0:\n",
        "        list_.append('E')\n",
        "    elif check.loc[i]['Traffic_cond'] == 'high' and check.loc[i]['Road_cond'] == 'good' and check.loc[i]['opp_dist']>20:\n",
        "        list_.append('D')\n",
        "    elif check.loc[i]['Road_cond'] == 'high' and check.loc[i]['Traffic_cond'] == 'good' and check.loc[i]['opp_dist']>50:\n",
        "        list_.append('C')\n",
        "    elif check.loc[i]['opp_dist'] >20 and check.loc[i]['Road_cond'] == 'good' and check.loc[i]['Traffic_cond'] == 'mod':\n",
        "        list_.append('C')\n",
        "    elif check.loc[i]['Traffic_cond'] == 'high' and check.loc[i]['vis'] == 1 and check.loc[i]['Road_cond']=='good' and check.loc[i]['opp_dist']>60:\n",
        "        list_.append('B')\n",
        "    elif check.loc[i]['Traffic_cond'] == 'mod' and check.loc[i]['vis'] == 1 and check.loc[i]['Road_cond']=='good' and check.loc[i]['opp_dist']>50:\n",
        "        list_.append('B')\n",
        "    elif check.loc[i]['Traffic_cond'] == 'mod' and check.loc[i]['vis'] == 1 and check.loc[i]['Road_cond']=='good' and check.loc[i]['opp_dist']>30:\n",
        "        list_.append('C')\n",
        "    elif check.loc[i]['Traffic_cond'] == 'high' and check.loc[i]['vis'] == 1 and check.loc[i]['Road_cond']=='good' and check.loc[i]['opp_dist']<30:\n",
        "        list_.append('C')\n",
        "    elif check.loc[i]['Traffic_cond'] == 'high' and check.loc[i]['vis'] == 1 and check.loc[i]['Road_cond']=='good' and check.loc[i]['opp_dist']<20:\n",
        "        list_.append('D')\n",
        "    elif check.loc[i]['Traffic_cond'] == 'low' and check.loc[i]['vis'] == 1 and check.loc[i]['Road_cond']=='good' and check.loc[i]['opp_dist']>50:\n",
        "        list_.append('A')\n",
        "    elif check.loc[i]['Traffic_cond'] == 'mod' and check.loc[i]['vis'] == 1 and check.loc[i]['Road_cond']=='good' and check.loc[i]['opp_dist']>50:\n",
        "        list_.append('A')\n",
        "    elif check.loc[i]['Traffic_cond'] == 'low' and check.loc[i]['vis'] == 1 and check.loc[i]['Road_cond']=='bad' and check.loc[i]['opp_dist']>20:\n",
        "        list_.append('C')\n",
        "    elif check.loc[i]['Traffic_cond'] == 'mod' and check.loc[i]['vis'] == 1 and check.loc[i]['Road_cond']=='bad' and check.loc[i]['opp_dist']>20:\n",
        "        list_.append('C')\n",
        "    else:\n",
        "        list_.append('E')\n",
        "\n",
        "\n",
        "check['Recommended'] = list_\n",
        "check.to_csv('ML_data.csv')\n",
        "\n",
        "files.download('ML_data.csv')\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EDozlMgeN-u5",
        "outputId": "435a3de7-1ac1-4ecd-dee0-234091b953ab"
      },
      "source": [
        "def check_road(i):\n",
        "    if i == 'good':\n",
        "        return(1)\n",
        "    return 0\n",
        "def check_traffic(i):\n",
        "    if i =='high':\n",
        "        return(2)\n",
        "    elif i =='mod':\n",
        "        return(1)\n",
        "    return 0\n",
        "check['Road_cond'] =check['Road_cond'].apply(lambda x: check_road(x))\n",
        "check['Traffic_cond'] = check['Traffic_cond'].apply(lambda x: check_traffic(x))\n",
        "\n",
        "\n",
        "check_dummy = pd.get_dummies(check.iloc[:,:-1])\n",
        "X =check_dummy.values\n",
        "y = check.iloc[:,-1].values\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder as Le\n",
        "encoder = Le()\n",
        "y_enc = encoder.fit_transform(y)\n",
        "\n",
        "from sklearn.model_selection import train_test_split as tts\n",
        "X_train,X_test,y_train,y_test = tts(X,y_enc,test_size = 0.3)\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier as RFC\n",
        "cls = RFC()\n",
        "cls.fit(X_train,y_train)\n",
        "\n",
        "pred = cls.predict(X_test)\n",
        "\n",
        "from sklearn.metrics import accuracy_score as acc\n",
        "print(acc(y_test,pred))\n",
        "\n",
        "import pickle\n",
        "filename = 'model.sav'\n",
        "pickle.dump(cls,open(filename,'wb'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}